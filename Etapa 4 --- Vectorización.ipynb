{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formas de caracterizar en contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos los siguientes experimentos para ver la mejor forma de caracterizar el contexto:\n",
    "    - bolsa de palabras (unigramas, bigramas, subwords, con y sin stopwords) \n",
    "    - Agregado por mi: tfidf con normalización para poner algunos pesos en las palabras\n",
    "    - si hay interacción del usuario objetivo y cómo se representa\n",
    "    - si hay respuestas\n",
    "    - si hay multimedia y de qué tipo\n",
    "__COMPLETAR__\n",
    "\n",
    "__PREGUNTAR:\n",
    "si hay interacción del usuario objetivo y cómo se representa??. si hay respuestas??__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos diferentes word embeddings, obtenidos de diferentes tipos de corpus: genéricos o específicos de lenguaje generado por usuario o específicos del corpus del que estamos aprendiendo.\n",
    "    - Es decir, tres diferentes tipos de word embeddings:\n",
    "      - SBWCE\n",
    "      - con el mismo corpus de chats\n",
    "      - con un corpus de twitter\n",
    "      \n",
    "__BUSCAR CORPUS DE TWITTER__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('short_ans3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acordandonos de los datos.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.context.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idchat</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.facebook.com/story.php?story_fbid=14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>https://m.facebook.com/story.php?story_fbid=14...</td>\n",
       "      <td>nonDef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>😂😂😂😂😂😂😂😂😂😂. Que es este lugar 👀. Qur hace este...</td>\n",
       "      <td>Bienvenido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bienvenido. Vengo a pasarle fotos obscenas e i...</td>\n",
       "      <td>👀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>👀. El mundo de nunca jamas?)</td>\n",
       "      <td>😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>😂😂</td>\n",
       "      <td>😂😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>😂😂😂</td>\n",
       "      <td>Oh sii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh sii. Seremos niños por siempre</td>\n",
       "      <td>Quienes ? 👀😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Quienes ? 👀😂</td>\n",
       "      <td>Yo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Yo. 😏</td>\n",
       "      <td>😏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>😏</td>\n",
       "      <td>😏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>😏</td>\n",
       "      <td>😏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>😏. Jajaja Eso si que es bastante creativo. ¡Mu...</td>\n",
       "      <td>😎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>😎</td>\n",
       "      <td>🌚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>🌚. 🌚</td>\n",
       "      <td>😏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>😏</td>\n",
       "      <td>Holaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Holaaa</td>\n",
       "      <td>Holaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Holaaaaa. 🇻🇪. Que yo me desaparezca, no hay li...</td>\n",
       "      <td>😱😱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>😱😱. Quien?. Jajaj. mira qué adulador es nuestr...</td>\n",
       "      <td>😏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>😏. 😄 siempre. Bueno no</td>\n",
       "      <td>Esperando este mensaje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>Esperando este mensaje</td>\n",
       "      <td>😪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>😪. 🤔. Siempre estuve acá vigilandolos👀?)</td>\n",
       "      <td>con quién no?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>con quién no?</td>\n",
       "      <td>😄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>😄. 🙈</td>\n",
       "      <td>más te vale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>más te vale</td>\n",
       "      <td>Contigo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>Contigo. 😂😂😂. 😏😏😏*</td>\n",
       "      <td>eso lo sé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>eso lo sé. jajajajaja. sólo tiene ojos para ti</td>\n",
       "      <td>👀👀👀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>👀👀👀</td>\n",
       "      <td>chicos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>chicos. una pregunta. cómo se escribe la direc...</td>\n",
       "      <td>ummmm okok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>ummmm okok. pero cómo?. 2da av las flores de p...</td>\n",
       "      <td>ummm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56749</th>\n",
       "      <td>181</td>\n",
       "      <td>Jonyyy. Siii. Yo vooyh</td>\n",
       "      <td>De unaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56750</th>\n",
       "      <td>181</td>\n",
       "      <td>De unaa. Quienes van a ir?</td>\n",
       "      <td>Nosee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56751</th>\n",
       "      <td>181</td>\n",
       "      <td>Nosee. Pensaba q iba a ir solo. Jajaja</td>\n",
       "      <td>Vamooo de unaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56752</th>\n",
       "      <td>181</td>\n",
       "      <td>Vamooo de unaa. Cuanto salem. ?. Que cosa cuan...</td>\n",
       "      <td>Lo de mañana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56753</th>\n",
       "      <td>181</td>\n",
       "      <td>Lo de mañana. Supongo que no más de 100. No sa...</td>\n",
       "      <td>Jajajajajajaja noo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56754</th>\n",
       "      <td>181</td>\n",
       "      <td>Jajajajajajaja noo. Es birra, pizzas y narguil...</td>\n",
       "      <td>Y este jueves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56755</th>\n",
       "      <td>181</td>\n",
       "      <td>Y este jueves. No me llegó nada. Como sabees</td>\n",
       "      <td>&lt;Archivo omitido&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56756</th>\n",
       "      <td>181</td>\n",
       "      <td>&lt;Archivo omitido&gt;. Soy RRPP de hillel ahora. A...</td>\n",
       "      <td>Aaag noo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56757</th>\n",
       "      <td>181</td>\n",
       "      <td>Aaag noo. En el centro encima. Pensé q era lo ...</td>\n",
       "      <td>Sos un culiado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56758</th>\n",
       "      <td>181</td>\n",
       "      <td>Sos un culiado. 😂😂😂😂</td>\n",
       "      <td>Jjajajajajajau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56759</th>\n",
       "      <td>181</td>\n",
       "      <td>Jjajajajajajau. No sabia q ya tenías pasaje</td>\n",
       "      <td>Sisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56760</th>\n",
       "      <td>181</td>\n",
       "      <td>Sisis. Ya tengo :p</td>\n",
       "      <td>Sarpaooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56761</th>\n",
       "      <td>181</td>\n",
       "      <td>Sarpaooo. En realidad en estos días los saque....</td>\n",
       "      <td>ah sarpado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56762</th>\n",
       "      <td>181</td>\n",
       "      <td>ah sarpado</td>\n",
       "      <td>Vos que ondaa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56763</th>\n",
       "      <td>181</td>\n",
       "      <td>Vos que ondaa?. Che... nos tenemos que juntar ...</td>\n",
       "      <td>See</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56764</th>\n",
       "      <td>181</td>\n",
       "      <td>See. Que sale más barato</td>\n",
       "      <td>Ansiosooo yoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56765</th>\n",
       "      <td>181</td>\n",
       "      <td>Ansiosooo yoo. Jajajajaja. Que bieeenn</td>\n",
       "      <td>Jajajajajajajajajajaja yo tmb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56766</th>\n",
       "      <td>181</td>\n",
       "      <td>Jajajajajajajajajajaja yo tmb. Y hasta cuando?...</td>\n",
       "      <td>See</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56767</th>\n",
       "      <td>181</td>\n",
       "      <td>See. Te va a salir lo mismo que sacar de ida y...</td>\n",
       "      <td>Ahh mortal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56768</th>\n",
       "      <td>181</td>\n",
       "      <td>Ahh mortal. Claro sisi. Y no se pueden sacar p...</td>\n",
       "      <td>Uh, 5 meses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56769</th>\n",
       "      <td>181</td>\n",
       "      <td>Uh, 5 meses. Sarpado. Tengo solo el pasaje de ...</td>\n",
       "      <td>Jajajajqjqjajaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56770</th>\n",
       "      <td>181</td>\n",
       "      <td>Jajajajqjqjajaja. Tendrías q averiguar</td>\n",
       "      <td>Si 😨😨😨😨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56771</th>\n",
       "      <td>181</td>\n",
       "      <td>Si 😨😨😨😨. A lo sumo si te exigen te sacas el pa...</td>\n",
       "      <td>Uh bajon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56772</th>\n",
       "      <td>181</td>\n",
       "      <td>Uh bajon. Bue. Tenes tiempo aun</td>\n",
       "      <td>Sisi obviamente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56773</th>\n",
       "      <td>181</td>\n",
       "      <td>Sisi obviamente. Tengo tiempo. No voy a poder ...</td>\n",
       "      <td>Jajajajajajajaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56774</th>\n",
       "      <td>181</td>\n",
       "      <td>Jajajajajajajaja. Yo nose culiado. No me qu da...</td>\n",
       "      <td>No tengo nada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56775</th>\n",
       "      <td>181</td>\n",
       "      <td>No tengo nada. Jajajajajaja. No preparé nada</td>\n",
       "      <td>Jajajajajaja que culia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56776</th>\n",
       "      <td>181</td>\n",
       "      <td>Jajajajajaja que culia. Y seguro de salud ni n...</td>\n",
       "      <td>Jajajajjaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56777</th>\n",
       "      <td>181</td>\n",
       "      <td>Jajajajjaa. Hospedaje?. Tengo para las primera...</td>\n",
       "      <td>Jajajaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56778</th>\n",
       "      <td>181</td>\n",
       "      <td>Jajajaja. Estaba pensando hacer lo mismo</td>\n",
       "      <td>Jajajaja</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56779 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idchat                                            context  \\\n",
       "0           0                                                NaN   \n",
       "1           0  https://m.facebook.com/story.php?story_fbid=14...   \n",
       "2           1  😂😂😂😂😂😂😂😂😂😂. Que es este lugar 👀. Qur hace este...   \n",
       "3           1  Bienvenido. Vengo a pasarle fotos obscenas e i...   \n",
       "4           1                       👀. El mundo de nunca jamas?)   \n",
       "5           1                                                 😂😂   \n",
       "6           1                                                😂😂😂   \n",
       "7           1                  Oh sii. Seremos niños por siempre   \n",
       "8           1                                       Quienes ? 👀😂   \n",
       "9           1                                              Yo. 😏   \n",
       "10          1                                                  😏   \n",
       "11          1                                                  😏   \n",
       "12          1  😏. Jajaja Eso si que es bastante creativo. ¡Mu...   \n",
       "13          1                                                  😎   \n",
       "14          1                                               🌚. 🌚   \n",
       "15          1                                                  😏   \n",
       "16          1                                             Holaaa   \n",
       "17          1  Holaaaaa. 🇻🇪. Que yo me desaparezca, no hay li...   \n",
       "18          1  😱😱. Quien?. Jajaj. mira qué adulador es nuestr...   \n",
       "19          1                             😏. 😄 siempre. Bueno no   \n",
       "20          1                             Esperando este mensaje   \n",
       "21          1           😪. 🤔. Siempre estuve acá vigilandolos👀?)   \n",
       "22          1                                      con quién no?   \n",
       "23          1                                               😄. 🙈   \n",
       "24          1                                        más te vale   \n",
       "25          1                                 Contigo. 😂😂😂. 😏😏😏*   \n",
       "26          1     eso lo sé. jajajajaja. sólo tiene ojos para ti   \n",
       "27          1                                                👀👀👀   \n",
       "28          1  chicos. una pregunta. cómo se escribe la direc...   \n",
       "29          1  ummmm okok. pero cómo?. 2da av las flores de p...   \n",
       "...       ...                                                ...   \n",
       "56749     181                             Jonyyy. Siii. Yo vooyh   \n",
       "56750     181                         De unaa. Quienes van a ir?   \n",
       "56751     181             Nosee. Pensaba q iba a ir solo. Jajaja   \n",
       "56752     181  Vamooo de unaa. Cuanto salem. ?. Que cosa cuan...   \n",
       "56753     181  Lo de mañana. Supongo que no más de 100. No sa...   \n",
       "56754     181  Jajajajajajaja noo. Es birra, pizzas y narguil...   \n",
       "56755     181       Y este jueves. No me llegó nada. Como sabees   \n",
       "56756     181  <Archivo omitido>. Soy RRPP de hillel ahora. A...   \n",
       "56757     181  Aaag noo. En el centro encima. Pensé q era lo ...   \n",
       "56758     181                               Sos un culiado. 😂😂😂😂   \n",
       "56759     181        Jjajajajajajau. No sabia q ya tenías pasaje   \n",
       "56760     181                                 Sisis. Ya tengo :p   \n",
       "56761     181  Sarpaooo. En realidad en estos días los saque....   \n",
       "56762     181                                         ah sarpado   \n",
       "56763     181  Vos que ondaa?. Che... nos tenemos que juntar ...   \n",
       "56764     181                           See. Que sale más barato   \n",
       "56765     181             Ansiosooo yoo. Jajajajaja. Que bieeenn   \n",
       "56766     181  Jajajajajajajajajajaja yo tmb. Y hasta cuando?...   \n",
       "56767     181  See. Te va a salir lo mismo que sacar de ida y...   \n",
       "56768     181  Ahh mortal. Claro sisi. Y no se pueden sacar p...   \n",
       "56769     181  Uh, 5 meses. Sarpado. Tengo solo el pasaje de ...   \n",
       "56770     181             Jajajajqjqjajaja. Tendrías q averiguar   \n",
       "56771     181  Si 😨😨😨😨. A lo sumo si te exigen te sacas el pa...   \n",
       "56772     181                    Uh bajon. Bue. Tenes tiempo aun   \n",
       "56773     181  Sisi obviamente. Tengo tiempo. No voy a poder ...   \n",
       "56774     181  Jajajajajajajaja. Yo nose culiado. No me qu da...   \n",
       "56775     181       No tengo nada. Jajajajajaja. No preparé nada   \n",
       "56776     181  Jajajajajaja que culia. Y seguro de salud ni n...   \n",
       "56777     181  Jajajajjaa. Hospedaje?. Tengo para las primera...   \n",
       "56778     181           Jajajaja. Estaba pensando hacer lo mismo   \n",
       "\n",
       "                                                   label  \n",
       "0      https://m.facebook.com/story.php?story_fbid=14...  \n",
       "1                                                 nonDef  \n",
       "2                                             Bienvenido  \n",
       "3                                                      👀  \n",
       "4                                                     😂😂  \n",
       "5                                                    😂😂😂  \n",
       "6                                                 Oh sii  \n",
       "7                                           Quienes ? 👀😂  \n",
       "8                                                     Yo  \n",
       "9                                                      😏  \n",
       "10                                                     😏  \n",
       "11                                                     😏  \n",
       "12                                                     😎  \n",
       "13                                                     🌚  \n",
       "14                                                     😏  \n",
       "15                                                Holaaa  \n",
       "16                                              Holaaaaa  \n",
       "17                                                    😱😱  \n",
       "18                                                     😏  \n",
       "19                                Esperando este mensaje  \n",
       "20                                                     😪  \n",
       "21                                         con quién no?  \n",
       "22                                                     😄  \n",
       "23                                           más te vale  \n",
       "24                                               Contigo  \n",
       "25                                             eso lo sé  \n",
       "26                                                   👀👀👀  \n",
       "27                                                chicos  \n",
       "28                                            ummmm okok  \n",
       "29                                                  ummm  \n",
       "...                                                  ...  \n",
       "56749                                            De unaa  \n",
       "56750                                              Nosee  \n",
       "56751                                     Vamooo de unaa  \n",
       "56752                                       Lo de mañana  \n",
       "56753                                 Jajajajajajaja noo  \n",
       "56754                                      Y este jueves  \n",
       "56755                                  <Archivo omitido>  \n",
       "56756                                           Aaag noo  \n",
       "56757                                     Sos un culiado  \n",
       "56758                                     Jjajajajajajau  \n",
       "56759                                              Sisis  \n",
       "56760                                           Sarpaooo  \n",
       "56761                                         ah sarpado  \n",
       "56762                                     Vos que ondaa?  \n",
       "56763                                                See  \n",
       "56764                                      Ansiosooo yoo  \n",
       "56765                      Jajajajajajajajajajaja yo tmb  \n",
       "56766                                                See  \n",
       "56767                                         Ahh mortal  \n",
       "56768                                        Uh, 5 meses  \n",
       "56769                                   Jajajajqjqjajaja  \n",
       "56770                                            Si 😨😨😨😨  \n",
       "56771                                           Uh bajon  \n",
       "56772                                    Sisi obviamente  \n",
       "56773                                   Jajajajajajajaja  \n",
       "56774                                      No tengo nada  \n",
       "56775                             Jajajajajaja que culia  \n",
       "56776                                         Jajajajjaa  \n",
       "56777                                           Jajajaja  \n",
       "56778                                           Jajajaja  \n",
       "\n",
       "[56779 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como habíamos dicho es mejor pre procesar las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = punctuation + '¡' + '¿'\n",
    "\n",
    "def dig2num(text):\n",
    "    return re.sub('(\\d+[\\WxX]*[^ ]*)+', 'NUM', text)\n",
    "\n",
    "def rm_tildes(text):\n",
    "    return ''.join((c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn'))\n",
    "\n",
    "def rm_media(text):\n",
    "    return re.sub(r'<archivo omitido>|<media omitted>', 'MEDIA', text)\n",
    "\n",
    "def rm_repeated(text):\n",
    "    return re.sub(r'([aeourshmi])\\1{2,}', r'\\1', text)\n",
    "\n",
    "def rm_ok(text):\n",
    "    return re.sub('(ok)+[akis]*', 'ok', text)\n",
    "\n",
    "def rm_sw(text):\n",
    "    return re.sub('{1}{0}{1}'.format(STOP_WORDS, '[]'), '', text)\n",
    "\n",
    "def rm_ja(text):\n",
    "    return re.sub('(ja[ja(js)]*)+', 'ja', text)\n",
    "\n",
    "def rm_si(text):\n",
    "    return re.sub('[s]+[i]+', 'si', text)\n",
    "\n",
    "def to_low(text):\n",
    "    return text.lower()\n",
    "\n",
    "def clean_text(text):\n",
    "    return rm_media(rm_tildes(to_low(text)))\n",
    "\n",
    "def clean_text_1(text):\n",
    "    return dig2num(rm_si(rm_ok(rm_ja(rm_repeated(rm_sw(clean_text(text)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     httpsmfacebookcomstoryphpstoryfbidNUM hola te ...\n",
       "2     😂😂😂😂😂😂😂😂😂😂 que es este lugar 👀 qur hace este a...\n",
       "3     bienvenido vengo a pasarle fotos obscenas e ir...\n",
       "4                             👀 el mundo de nunca jamas\n",
       "5                                                    😂😂\n",
       "6                                                   😂😂😂\n",
       "7                       oh si seremos ninos por siempre\n",
       "8                                           quienes  👀😂\n",
       "9                                                  yo 😏\n",
       "10                                                    😏\n",
       "11                                                    😏\n",
       "12     😏 ja eso si que es bastante creativo muy bueno 😄\n",
       "13                                                    😎\n",
       "14                                                  🌚 🌚\n",
       "15                                                    😏\n",
       "16                                                 hola\n",
       "17    hola 🇻🇪 que yo me desaparezca no hay lio pero ...\n",
       "18    😱😱 quien ja mira que adulador es nuestro migue...\n",
       "19                                 😏 😄 siempre bueno no\n",
       "20                               esperando este mensaje\n",
       "21                 😪 🤔 siempre estuve aca vigilandolos👀\n",
       "22                                         con quien no\n",
       "23                                                  😄 🙈\n",
       "24                                          mas te vale\n",
       "25                                      contigo 😂😂😂 😏😏😏\n",
       "26                 eso lo se ja solo tiene ojos para ti\n",
       "27                                                  👀👀👀\n",
       "28    chicos una pregunta como se escribe la direcci...\n",
       "29    um ok pero como NUM av las flores de pte hierr...\n",
       "30    um no recuerdo si hay algo mas perp creo q es ...\n",
       "Name: context, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df[1:].context.map(clean_text_1)\n",
    "df_cleaned.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOG: 1-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, preprocessor=clean_text_1, ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = vectorizer.fit(df[1:].context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces obtenemos alrededor de tantas features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEDIA', 'NUM', 'aNUM', 'aa', 'aah', 'aaja', 'abajo', 'abi', 'abierta', 'abiertas', 'abierto', 'abra', 'abran', 'abrazo', 'abrazos', 'abre', 'abren', 'abri', 'abril', 'abrir', 'abro', 'abuela', 'abuelo', 'aburrido', 'abuso', 'aca', 'acaba', 'acaban', 'acabar', 'acabaron', 'acabas', 'acabe', 'acabo', 'academia', 'acaso', 'acceder', 'acceso', 'accion', 'acepta', 'acepte', 'acepto', 'acerca', 'aclarar', 'aclaro', 'acompana', 'acompanar', 'acompano', 'acordaba', 'acordar', 'acordas', 'acordate', 'acorde', 'actitud', 'activa', 'activan', 'activar', 'active', 'actividad', 'actividades', 'activo', 'activos', 'acto', 'actores', 'actual', 'actualiza', 'actualizacion', 'actualizar', 'actualizo', 'acuerda', 'acuerdan', 'acuerdo', 'acv', 'add', 'adelantar', 'adelante', 'adelanto', 'ademas', 'adentro', 'adios', 'adjuntado', 'admin', 'administrador', 'adri', 'adrian', 'aeropuerto', 'afecta', 'afiche', 'after', 'afuera', 'again', 'agarra', 'agarrar', 'agarre', 'agarro', 'age', 'agenda', 'agendado', 'agendo', 'ago', 'agosto']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5394"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(representation.get_feature_names()[:100])\n",
    "len(representation.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOG = representation.transform(df[1:].context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1274)\t1\n",
      "  (0, 2425)\t1\n",
      "  (0, 2458)\t1\n",
      "  (0, 3442)\t1\n",
      "  (0, 4807)\t1\n",
      "  (1, 297)\t1\n",
      "  (1, 1766)\t1\n",
      "  (1, 1855)\t2\n",
      "  (1, 2320)\t1\n",
      "  (1, 2954)\t1\n",
      "  (1, 4164)\t1\n",
      "  (1, 4222)\t1\n",
      "  (2, 517)\t1\n",
      "  (2, 2094)\t1\n",
      "  (2, 2621)\t1\n",
      "  (2, 3672)\t1\n",
      "  (2, 5193)\t1\n",
      "  (3, 1274)\t1\n",
      "  (3, 1613)\t1\n",
      "  (3, 2643)\t1\n",
      "  (3, 3299)\t1\n",
      "  (3, 3444)\t1\n",
      "  (6, 3381)\t1\n",
      "  (6, 3473)\t1\n",
      "  (6, 3939)\t1\n",
      "  (6, 4608)\t1\n",
      "  (6, 4610)\t1\n",
      "  (7, 4203)\t1\n",
      "  (8, 5379)\t1\n"
     ]
    }
   ],
   "source": [
    "print(BOG[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOG: 2-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 2),\n",
       "        preprocessor=<function clean_text_1 at 0x7fafab945c80>,\n",
       "        stop_words=None, strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation.set_params(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14403"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(representation.fit(df[1:].context).get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOG: 3-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3),\n",
       "        preprocessor=<function clean_text_1 at 0x7fafab945c80>,\n",
       "        stop_words=None, strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation.set_params(ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17048"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(representation.fit(df[1:].context).get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOG_matrix = representation.transform(df[1:].context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56778, 17048)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOG_matrix.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicos. una pregunta. cómo se escribe la dirección postal en vuestras ciudades?. es que los otros días vi una de francia y es un poco diferente a como yo escribo la mía. La de aca por donde vivo es 1010. El cod postal. así que si pongo n un sobre 1010 te llega?. Pero es por zona, no se si s igual por alla. qué raro sois los venezolanos. no?. No, obvio pones la direccion😂😂'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.context[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ NUM: 2, aca: 1, aca por: 1, alla: 1, asi: 1, asi que: 1, asi que si: 1, chicos: 1, chicos una: 1, ciudades: 1, cod: 1, como: 2, como se: 1, como yo: 1, de: 2, de aca: 1, dias: 1, diferente: 1, direccion: 2, donde: 1, en: 1, es: 4, es NUM: 1, es por: 1, es que: 1, es un: 1, es un poco: 1, escribe: 1, escribo: 1, igual: 1, igual por: 1, la: 4, la de: 1, la direccion: 2, la mia: 1, llega: 1, los: 2, los otros: 1, mia: 1, no: 3, no no: 1, no se: 1, no se si: 1, obvio: 1, otros: 1, pero: 1, pero es: 1, poco: 1, pones: 1, pongo: 1, por: 3, por alla: 1, por donde: 1, pregunta: 1, que: 3, que los: 1, que raro: 1, que si: 1, raro: 1, se: 2, se escribe: 1, se si: 1, si: 2, si igual: 1, sobre: 1, un: 2, un poco: 1, una: 2, una de: 1, una pregunta: 1, vi: 1, vivo: 1, yo: 1, zona: 1, }"
     ]
    }
   ],
   "source": [
    "arr_repr = BOG_matrix[27].toarray()[0]\n",
    "print('{ ', end='')\n",
    "for i in BOG_matrix[27].indices:\n",
    "    print('{0}: {1}'.format(representation.get_feature_names()[i], arr_repr[i]), end=', ')\n",
    "print('}', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOG: (3,4)-Subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, stop_words=STOP_WORDS, preprocessor=clean_text_1, analyzer='char', ngram_range=(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(3, 4),\n",
       "        preprocessor=<function clean_text_1 at 0x7fafab945c80>,\n",
       "        stop_words='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~¡',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = vectorizer.fit(df[1:].context)\n",
    "BOG_matrix = representation.transform(df[1:].context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24863"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(representation.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicos. una pregunta. cómo se escribe la dirección postal en vuestras ciudades?. es que los otros días vi una de francia y es un poco diferente a como yo escribo la mía. La de aca por donde vivo es 1010. El cod postal. así que si pongo n un sobre 1010 te llega?. Pero es por zona, no se si s igual por alla. qué raro sois los venezolanos. no?. No, obvio pones la direccion😂😂'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.context[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NU: 2,  NUM: 2,  a : 1,  a c: 1,  ac: 1,  aca: 1,  al: 1,  all: 1,  as: 1,  asi: 1,  ci: 1,  ciu: 1,  co: 3,  cod: 1,  com: 2,  de: 2,  de : 2,  di: 4,  dia: 1,  dif: 1,  dir: 2,  do: 1,  don: 1,  en: 1,  en : 1,  es: 6,  es : 4,  esc: 2,  fr: 1,  fra: 1,  ig: 1,  igu: 1,  la: 4,  la : 4,  ll: 1,  lle: 1,  lo: 2,  los: 2,  mi: 1,  mia: 1,  n : 1,  no: 3,  no : 3,  ob: 1,  obv: 1,  ot: 1,  otr: 1,  pe: 1,  per: 1,  po: 8,  poc: 1,  pon: 2,  por: 3,  pos: 2,  pr: 1,  pre: 1,  qu: 3,  que: 3,  ra: 1,  rar: 1,  s : 1,  se: 2,  se : 2,  si: 2,  si : 2,  so: 2,  sob: 1,  un: 4,  un : 2,  una: 2,  ve: 1,  ven: 1,  vi: 2,  vi : 1,  viv: 1,  vu: 1,  vue: 1,  y : 1,  y e: 1,  yo: 1,  yo : 1,  zo: 1,  zon: 1, M c: 1, M co: 1, M l: 1, M ll: 1, NUM: 2, NUM : 2, UM : 2, UM c: 1, UM l: 1, a c: 2, a co: 2, a d: 4, a de: 2, a di: 2, a l: 1, a la: 1, a m: 1, a mi: 1, a n: 1, a no: 1, a p: 3, a pe: 1, a po: 1, a pr: 1, a q: 1, a qu: 1, a y: 1, a y : 1, aca: 1, aca : 1, ade: 1, ades: 1, al : 3, al a: 1, al e: 1, al p: 1, all: 1, alla: 1, anc: 1, anci: 1, ano: 1, anos: 1, aro: 1, aro : 1, as : 2, as c: 1, as v: 1, asi: 1, asi : 1, be : 1, be l: 1, bo : 1, bo l: 1, bre: 1, bre : 1, bvi: 1, bvio: 1, ca : 1, ca p: 1, cci: 2, ccio: 2, chi: 1, chic: 1, cia: 1, cia : 1, cio: 2, cion: 2, ciu: 1, ciud: 1, co : 1, co d: 1, cod: 1, cod : 1, com: 2, como: 2, cos: 1, cos : 1, cri: 2, crib: 2, d p: 1, d po: 1, dad: 1, dade: 1, de : 3, de a: 1, de f: 1, de v: 1, des: 1, des : 1, dia: 1, dias: 1, dif: 1, dife: 1, dir: 2, dire: 2, don: 1, dond: 1, e N: 1, e NU: 1, e a: 2, e a : 1, e ac: 1, e e: 1, e es: 1, e f: 1, e fr: 1, e l: 2, e la: 1, e lo: 1, e r: 1, e ra: 1, e s: 2, e si: 2, e v: 1, e vi: 1, ecc: 2, ecci: 2, ega: 1, ega : 1, egu: 1, egun: 1, en : 1, en v: 1, ene: 1, enez: 1, ent: 1, ente: 1, ere: 1, eren: 1, ero: 1, ero : 1, es : 6, es N: 1, es e: 1, es l: 1, es p: 1, es q: 1, es u: 1, esc: 2, escr: 2, est: 1, estr: 1, ezo: 1, fer: 1, fere: 1, fra: 1, fran: 1, ga : 1, ga p: 1, go : 1, go n: 1, gua: 1, gual: 1, gun: 1, gunt: 1, hic: 1, hico: 1, i p: 1, i po: 1, i q: 1, i qu: 1, i s: 1, i u: 1, i un: 1, ia : 2, ia l: 1, ia y: 1, ias: 1, ias : 1, ibe: 1, ibe : 1, ibo: 1, ibo : 1, ico: 1, icos: 1, ife: 1, ifer: 1, igu: 1, igua: 1, io : 1, io p: 1, ion: 2, ion : 1, ire: 2, irec: 2, is : 1, is l: 1, iud: 1, iuda: 1, ivo: 1, ivo : 1, l a: 1, l as: 1, l e: 1, l en: 1, l p: 1, l po: 1, la : 5, la d: 3, la m: 1, la q: 1, lan: 1, lano: 1, leg: 1, lega: 1, lla: 1, lla : 1, lle: 1, lleg: 1, los: 2, los : 2, mia: 1, mia : 1, mo : 2, mo s: 1, mo y: 1, n p: 2, n po: 2, n s: 1, n so: 1, n u: 1, n un: 1, n v: 1, n vu: 1, na : 3, na d: 1, na n: 1, na p: 1, nci: 1, ncia: 1, nde: 1, nde : 1, nes: 1, nes : 1, nez: 1, ngo: 1, ngo : 1, no : 3, no n: 1, no o: 1, no s: 1, nos: 1, nos : 1, nta: 1, nta : 1, nte: 1, nte : 1, o d: 1, o di: 1, o e: 3, o es: 3, o l: 1, o la: 1, o n: 2, o n : 1, o no: 1, o o: 1, o ob: 1, o p: 1, o po: 1, o s: 3, o se: 2, o so: 1, o y: 1, o yo: 1, obr: 1, obre: 1, obv: 1, obvi: 1, oco: 1, oco : 1, od : 1, od p: 1, ois: 1, ois : 1, ola: 1, olan: 1, omo: 2, omo : 2, on : 1, on p: 1, ona: 1, ona : 1, ond: 1, onde: 1, one: 1, ones: 1, ong: 1, ongo: 1, or : 3, or a: 1, or d: 1, os : 5, os d: 1, os n: 1, os o: 1, os u: 1, os v: 1, ost: 2, osta: 2, otr: 1, otro: 1, per: 1, pero: 1, poc: 1, poco: 1, pon: 2, pone: 1, pong: 1, por: 3, por : 3, pos: 2, post: 2, pre: 1, preg: 1, que: 3, que : 3, r a: 1, r al: 1, r d: 1, r do: 1, r z: 1, ran: 1, ranc: 1, rar: 1, raro: 1, ras: 1, ras : 1, re : 1, re N: 1, rec: 2, recc: 2, reg: 1, regu: 1, ren: 1, rent: 1, rib: 2, ribe: 1, ribo: 1, ro : 2, ro e: 1, ro s: 1, ros: 1, ros : 1, s N: 1, s NU: 1, s c: 1, s ci: 1, s d: 1, s di: 1, s e: 1, s es: 1, s i: 1, s ig: 1, s l: 2, s la: 1, s lo: 1, s n: 1, s no: 1, s o: 1, s ot: 1, s p: 1, s po: 1, s q: 1, s qu: 1, s u: 2, s un: 2, s v: 2, s ve: 1, s vi: 1, scr: 2, scri: 2, se : 2, se e: 1, se s: 1, si : 3, si p: 1, si q: 1, si s: 1, sob: 1, sobr: 1, soi: 1, sta: 2, stal: 2, str: 1, stra: 1, ta : 1, ta c: 1, tal: 2, tal : 2, te : 1, te a: 1, tra: 1, tras: 1, tro: 1, tros: 1, ual: 1, ual : 1, uda: 1, udad: 1, ue : 3, ue l: 1, ue r: 1, ue s: 1, ues: 1, uest: 1, un : 2, un p: 1, un s: 1, una: 2, una : 2, unt: 1, unta: 1, ven: 1, vene: 1, vi : 1, vi u: 1, vio: 1, vio : 1, viv: 1, vivo: 1, vo : 1, vo e: 1, vue: 1, y e: 1, y es: 1, yo : 1, yo e: 1, zon: 1, zona: 1, "
     ]
    }
   ],
   "source": [
    "arr_repr = BOG_matrix[27].toarray()[0]\n",
    "for i in BOG_matrix[27].indices:\n",
    "    print('{0}: {1}'.format(representation.get_feature_names()[i], arr_repr[i]), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFidf: 1-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, preprocessor=clean_text_1, ngram_range=(1, 1), norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = vectorizer.fit(df[1:].context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOG_matrix = representation.transform(df[1:].context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces podemos decir que la frase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh sii. Seremos niños por siempre'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.context[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta representada como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4610)\t0.444007229186\n",
      "  (0, 4608)\t0.232292394347\n",
      "  (0, 3939)\t0.285705626552\n",
      "  (0, 3473)\t0.497750374311\n",
      "  (0, 3381)\t0.647699532027\n"
     ]
    }
   ],
   "source": [
    "print(BOG_matrix[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde los features son..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saca', 'sabor', 'peso', 'necesiten', 'moral')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation.get_feature_names()[4449], representation.get_feature_names()[4447], representation.get_feature_names()[3802], representation.get_feature_names()[3348], representation.get_feature_names()[3261]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFidf: 3-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, preprocessor=clean_text_1, ngram_range=(1, 3), norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = vectorizer.fit(df[1:].context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOG_matrix = representation.transform(df[1:].context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14962)\t0.251093106197\n",
      "  (0, 10991)\t0.526693785555\n",
      "  (0, 7090)\t0.708823214338\n",
      "  (0, 6946)\t0.34980486296\n",
      "  (0, 3044)\t0.186419196821\n",
      "  (1, 13416)\t0.445651009621\n",
      "  (1, 12802)\t0.260870206023\n",
      "  (1, 12700)\t0.114103432201\n",
      "  (1, 9129)\t0.312658204155\n",
      "  (1, 6600)\t0.238068586996\n",
      "  (1, 5707)\t0.481824210078\n",
      "  (1, 5161)\t0.445651009621\n",
      "  (1, 5101)\t0.145516231116\n",
      "  (1, 1117)\t0.337573917747\n",
      "  (2, 16328)\t0.45418585109\n",
      "  (2, 11596)\t0.520149510929\n",
      "  (2, 7360)\t0.463337136898\n",
      "  (2, 6171)\t0.360458478114\n",
      "  (2, 1504)\t0.422549502516\n",
      "  (3, 10995)\t0.391758851566\n",
      "  (3, 10264)\t0.471306759228\n",
      "  (3, 7671)\t0.549778867213\n",
      "  (3, 4420)\t0.514157183574\n",
      "  (3, 4180)\t0.175496199971\n",
      "  (3, 3044)\t0.164260806241\n",
      "  (6, 14494)\t0.354404835023\n",
      "  (6, 14225)\t0.185414881299\n",
      "  (6, 12162)\t0.22804911449\n",
      "  (6, 11046)\t0.602397708492\n",
      "  (6, 11040)\t0.397302403417\n",
      "  (6, 10463)\t0.51699123506\n",
      "  (7, 13366)\t1.0\n",
      "  (8, 16875)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(BOG_matrix[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces podemos decir que la frase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicos. una pregunta. cómo se escribe la dirección postal en vuestras ciudades?. es que los otros días vi una de francia y es un poco diferente a como yo escribo la mía. La de aca por donde vivo es 1010. El cod postal. así que si pongo n un sobre 1010 te llega?. Pero es por zona, no se si s igual por alla. qué raro sois los venezolanos. no?. No, obvio pones la direccion😂😂'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.context[28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta representada como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17044)\t0.122346591758\n",
      "  (0, 16875)\t0.0505344426973\n",
      "  (0, 16562)\t0.11856716976\n",
      "  (0, 16448)\t0.0876481532616\n",
      "  (0, 16023)\t0.114368515018\n",
      "  (0, 15958)\t0.111328285247\n",
      "  (0, 15924)\t0.109401534642\n",
      "  (0, 15876)\t0.09219704563\n",
      "  (0, 15780)\t0.10054062254\n",
      "  (0, 14590)\t0.0924285941421\n",
      "  (0, 14324)\t0.128110828987\n",
      "  (0, 14225)\t0.0864893830059\n",
      "  (0, 14003)\t0.092006694011\n",
      "  (0, 13890)\t0.139659678239\n",
      "  (0, 13857)\t0.0964611674483\n",
      "  (0, 13438)\t0.10145416588\n",
      "  (0, 13135)\t0.0891153203862\n",
      "  (0, 13097)\t0.123745147403\n",
      "  (0, 12956)\t0.104691433598\n",
      "  (0, 12700)\t0.108599777491\n",
      "  (0, 12378)\t0.0970086224212\n",
      "  (0, 12181)\t0.11697464841\n",
      "  (0, 12173)\t0.142325670723\n",
      "  (0, 12162)\t0.159565082391\n",
      "  (0, 12151)\t0.0983157920864\n",
      "  :\t:\n",
      "  (0, 5245)\t0.0841350833944\n",
      "  (0, 5237)\t0.113895987251\n",
      "  (0, 5102)\t0.11420940119\n",
      "  (0, 5101)\t0.184663219042\n",
      "  (0, 4632)\t0.043493175501\n",
      "  (0, 4027)\t0.0763201425025\n",
      "  (0, 3957)\t0.242623955266\n",
      "  (0, 3875)\t0.128906565576\n",
      "  (0, 3822)\t0.0942850049113\n",
      "  (0, 3058)\t0.120578921785\n",
      "  (0, 3044)\t0.0748627773091\n",
      "  (0, 2302)\t0.131095183094\n",
      "  (0, 2277)\t0.100379210455\n",
      "  (0, 2216)\t0.111830969225\n",
      "  (0, 2157)\t0.13886394165\n",
      "  (0, 2092)\t0.145546876183\n",
      "  (0, 2038)\t0.142325670723\n",
      "  (0, 2015)\t0.0806051631679\n",
      "  (0, 1217)\t0.136695750024\n",
      "  (0, 1212)\t0.0879948372376\n",
      "  (0, 1181)\t0.0641662197014\n",
      "  (0, 924)\t0.0966983428321\n",
      "  (0, 404)\t0.145546876183\n",
      "  (0, 389)\t0.0818514394602\n",
      "  (0, 158)\t0.0912586035071\n"
     ]
    }
   ],
   "source": [
    "print(BOG_matrix[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde los features son..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zona: 0.12234659175774053, yo: 0.050534442697347366, vivo: 0.11856716975995497, vi: 0.0876481532615862, una pregunta: 0.1143685150183527, una de: 0.11132828524748828, una: 0.10940153464161766, un poco: 0.09219704562998841, un: 0.10054062254010157, sobre: 0.09242859414211325, si igual: 0.1281108289871265, si: 0.0864893830059329, se si: 0.09200669401099533, se escribe: 0.13965967823906839, se: 0.09646116744828899, raro: 0.1014541658802468, que si: 0.0891153203862292, que raro: 0.12374514740338534, que los: 0.10469143359780607, que: 0.10859977749099453, pregunta: 0.09700862242124296, por donde: 0.11697464840972999, por alla: 0.14232567072328067, por: 0.15956508239073838, pongo: 0.09831579208638877, pones: 0.11587912544216117, poco: 0.085767058832565, pero es: 0.10377616506189986, pero: 0.05238518845298545, otros: 0.09759410557706343, obvio: 0.09968114551481815, no se si: 0.09274280158788244, no se: 0.06596438580282649, no no: 0.09500251833050471, no: 0.11351884900093571, mia: 0.11132828524748828, los otros: 0.11420940118955161, los: 0.10530462068028322, llega: 0.11199996861179086, la mia: 0.12182066131348711, la direccion: 0.264130180590944, la de: 0.10057517258490781, la: 0.15812530743968584, igual por: 0.13965967823906839, igual: 0.07116729752801136, escribo: 0.11502180995925212, escribe: 0.12345516770236246, es un poco: 0.14049844803858233, es un: 0.08643941409042437, es que: 0.08413508339439471, es por: 0.11389598725097232, es NUM: 0.11420940118955161, es: 0.184663219042431, en: 0.0434931755009734, donde: 0.07632014250248814, direccion: 0.24262395526578306, diferente: 0.1289065655764879, dias: 0.09428500491126841, de aca: 0.12057892178460922, de: 0.07486277730914422, como yo: 0.1310951830936827, como se: 0.10037921045534302, como: 0.111830969225467, cod: 0.13886394164970695, ciudades: 0.1455468761833439, chicos una: 0.14232567072328067, chicos: 0.08060516316789397, asi que si: 0.13669575002395862, asi que: 0.087994837237629, asi: 0.06416621970135543, alla: 0.09669834283206566, aca por: 0.1455468761833439, aca: 0.08185143946016502, NUM: 0.09125860350705094, "
     ]
    }
   ],
   "source": [
    "dict_repr = dict()\n",
    "arr_repr = BOG_matrix[27].toarray()[0]\n",
    "for i in BOG_matrix[27].indices:\n",
    "    print('{0}: {1}'.format(representation.get_feature_names()[i], arr_repr[i]), end=', ')\n",
    "    dict_repr[representation.get_feature_names()[i]] = arr_repr[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras más representativas para la frase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('la direccion', 0.26413018059094401),\n",
       " ('direccion', 0.24262395526578306),\n",
       " ('es', 0.18466321904243099),\n",
       " ('por', 0.15956508239073838),\n",
       " ('la', 0.15812530743968584),\n",
       " ('ciudades', 0.14554687618334389),\n",
       " ('aca por', 0.14554687618334389),\n",
       " ('por alla', 0.14232567072328067),\n",
       " ('chicos una', 0.14232567072328067),\n",
       " ('es un poco', 0.14049844803858233)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict_repr.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues claramente esta pidiendo una dirección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos algunos embeddings de:\n",
    "- [SBWCE](http://crscardellino.me/SBWCE/) --> 300 dimensiones\n",
    "- Nuestro corupus --> 100 dimensiones\n",
    "\n",
    "**TWITER???**\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SBWCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos cargando los vectores pre-entrenados con el algoritmo de Word2Vec. Para ello usaremos Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('embeddings/SBW-vectors-300-min5.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma no nos alcanza la memoria (por ahora), por lo que vamos a filtrar las palabras que usaremos y guardaremos un nuevo archivo más pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Achicando el vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_words = Counter(chain.from_iterable(df_cleaned.map(lambda x: x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word2vec = open('embeddings/new_vector_SBW.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings/SBW-vectors-300-min5.txt') as wordvecs:\n",
    "    for line in wordvecs:\n",
    "        word = line.split(' ')\n",
    "        word, features = word[0], word[1:]\n",
    "        if word in distribution_words:\n",
    "            new_word2vec.write(word + ' ' + ' '.join(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word2vec.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargando nuevamente los vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('embeddings/new_vector_SBW.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inn', 0.5931442975997925),\n",
       " ('galta', 0.5310695171356201),\n",
       " ('fikk', 0.5252362489700317),\n",
       " ('riki', 0.5229285359382629),\n",
       " ('jag', 0.5188263654708862),\n",
       " ('sista', 0.5183577537536621),\n",
       " ('jah', 0.5087394714355469),\n",
       " ('yax', 0.5061405897140503),\n",
       " ('findes', 0.5053848028182983),\n",
       " ('dane', 0.5039175748825073)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cargando el corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos nuestro corpus para entrenar nuestro word2vec con los siguientes parametros:\n",
    "\n",
    "  - Minima frecuencia de palabra: 5\n",
    "  - Negative samples=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Guardando el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=df_cleaned.map(lambda x: x.split(' ')), min_count=5, negative=20, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('embeddings/chat.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cargando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('embeddings/chat.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dale', 0.8620980381965637),\n",
       " ('👍🏻', 0.7748069763183594),\n",
       " ('buenisimo', 0.7722575664520264),\n",
       " ('listo', 0.7669600248336792),\n",
       " ('😬', 0.7667552828788757),\n",
       " ('avisame', 0.7547341585159302),\n",
       " ('gobbi', 0.7463787198066711),\n",
       " ('dani', 0.7325387001037598),\n",
       " ('😁', 0.7173537015914917),\n",
       " ('naho', 0.7016512155532837)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pero como vectorizamos un contexto??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera opción fue sumar todos los vectores de palabras en un texto y así teníamos una representación del todo el contexto.\n",
    "\n",
    "Claramente aparecía un gran problema...\n",
    "- Que pasa si los contextos son similares pero tienen una longitud distinta... entonces iban a estar en espacios diferentes :o\n",
    "\n",
    "La simple solución fue promediarlo con la longitud del contexto y perfecto\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_to_vect(context):\n",
    "    return np.array([\n",
    "        np.mean([word2vec.get_vector(w)\n",
    "                 for w in context if w in word2vec.get_vocab()]\n",
    "                or [np.zeros(self.word2vec.get_dim())], axis=0)\n",
    "        for context in df_cleaned.map(lambda x: x.split())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
