{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empezar a experimentar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. clases de repuestas cortas con 3 palabras que ocurren más de n veces (k clases)\n",
    "    1. contexto de turnos anteriores del otro usuario hasta encontrar respuesta del mismo usuario\n",
    "        1. unigramas (que ocurren más de m veces)\n",
    "            1. unigramas (que ocurren más de 10 veces)\n",
    "            2. unigramas (que ocurren más de 20 veces)\n",
    "        2. unigramas (que ocurren más de m veces) y bigramas (que ocurren más de p veces)\n",
    "        3. unigramas (que ocurren más de m veces) y bigramas (que ocurren más de p veces) y subwords (que ocurren más de r veces)\n",
    "        4. subwords (que ocuren más de r veces)\n",
    "    2. contexto de 1 turno anterior\n",
    "        1. unigramas (que ocurren más de m veces)\n",
    "            1. unigramas (que ocurren más de 10 veces)\n",
    "            2. unigramas (que ocurren más de 20 veces)\n",
    "        2. unigramas (que ocurren más de m veces) y bigramas (que ocurren más de p veces)\n",
    "        3. unigramas (que ocurren más de m veces) y bigramas (que ocurren más de p veces) y subwords (que ocurren más de r veces)\n",
    "        4. subwords (que ocuren más de r veces)\n",
    "    3. contexto de 3 turnos anteriores\n",
    "        1. unigramas (que ocurren más de m veces)\n",
    "            1. unigramas (que ocurren más de 10 veces)\n",
    "            2. unigramas (que ocurren más de 20 veces)\n",
    "        2. unigramas (que ocurren más de m veces) y bigramas (que ocurren más de p veces)\n",
    "        3. unigramas (que ocurren más de m veces) y bigramas (que ocurren más de p veces) y subwords (que ocurren más de r veces)\n",
    "        4. subwords (que ocuren más de r veces)\n",
    "    4. contexto de 10 turnos anteriores\n",
    "        1. unigramas (que ocurren más de m veces)\n",
    "            1. unigramas (que ocurren más de 10 veces)\n",
    "            2. unigramas (que ocurren más de 20 veces)\n",
    "        2. unigramas (que ocurren más de m veces) y bigramas (que ocurren más de p veces)\n",
    "        3. unigramas (que ocurren más de m veces) y bigramas (que ocurren más de p veces) y subwords (que ocurren más de r veces)\n",
    "        4. subwords (que ocuren más de r veces)\n",
    "2. clases de respuestas cortas con 2 palabras que ocurren más de n veces (k clases)\n",
    "3. clases de respuestas cortas con 1 palabra que ocurren más de n veces (k clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como primera iteración, hacer experimentos con:\n",
    "- unigramas y bigramas de palabras y trigramas de letras (incluyendo espacios en blanco) (subwords) que ocurren más de m, p y r veces en el contexto, respectivamente\n",
    "- contexto de 1, 3 y 10 turnos anteriores\n",
    "- clases de 2 y 1-3 palabras\n",
    "\n",
    "Cada experimento hacerlo con SVM, Logistic Regression, Decision Trees, Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - seleccionar del corpus los ejemplos que cumplan con esa condición (que ocurran más de k veces en el corpus), junto con su contexto \n",
    "    - dividir los ejemplos en training, tuning y test\n",
    "    - definir clases objetivo\n",
    "           - todo el rango de respuestas cortas posibles que ocurren más de n veces (para diferentes valores de n)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- implementar el pipeline de clasificador y evaluación (en función de las clases)\n",
    "- buscar un clasificador que ofrezca múltiples resultados (múltiples clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases de respuestas cortas con 3 palabras que ocurren más de 10 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('short_ans3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('embeddings/chat.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"Xmatrix.pickle\"\n",
    "with open(filename, 'rb') as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X[:100]\n",
    "target = y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.size, len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "result = clf.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X[101:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>',\n",
       "       '<Media omitted>', '<Media omitted>', '<Media omitted>'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = result.predict(test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060606060606060608"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "must_predict = y[101:200]\n",
    "accuracy_score(must_predict, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
